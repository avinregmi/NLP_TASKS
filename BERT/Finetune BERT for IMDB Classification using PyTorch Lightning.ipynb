{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune BERT for Classification \n",
    "\n",
    "BERT can be used to perform many downstream tasks by modifying only few changes in the architecture. BERT performs pretty well in GLUE benchmark. Tasks in GLUE benchmark includes classifications, QA, etc\n",
    "\n",
    "![title](images/bert-tasks.png)\n",
    "\n",
    "\n",
    "We can make those changes to architecture ourselves or huggingface has provided modified architecture based on tasks. Modified architecture is simply base bert with some added head on top. \n",
    "\n",
    "**Some modified architecture for downstream tasks includes:**\n",
    "\n",
    "- [BertModel](https://huggingface.co/transformers/model_doc/bert.html#bertmodel):\n",
    "    The bare Bert Model transformer outputting raw hidden-states without any specific head on top. \n",
    "- [BertForPreTraining](https://huggingface.co/transformers/model_doc/bert.html#bertforpretraining): Bert Model with two heads on top as done during the pre-training: a masked language modeling head and a next sentence prediction (classification) head.\n",
    "- [BertForMaskedLM](https://huggingface.co/transformers/model_doc/bert.html#bertformaskedlm): Bert Model with a language modeling head on top.\n",
    "- [BertForNextSentencePrediction](https://huggingface.co/transformers/model_doc/bert.html#bertfornextsentenceprediction): Bert Model with a next sentence prediction (classification) head on top. \n",
    "- [BertForSequenceClassification](https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification): Bert Model transformer with a sequence classification/regression head on top (a linear layer on top of the pooled output) e.g. for GLUE tasks.\n",
    "- [BertForMultipleChoice](BertForMultipleChoice): Bert Model with a multiple choice classification head on top (a linear layer on top of the pooled output and a softmax) e.g. for RocStories/SWAG tasks.\n",
    "- [BertForTokenClassification](https://huggingface.co/transformers/model_doc/bert.html#bertfortokenclassification): Bert Model with a token classification head on top (a linear layer on top of the hidden-states output) e.g. for Named-Entity-Recognition (NER) tasks. \n",
    "- [BertForQuestionAnswering](https://huggingface.co/transformers/model_doc/bert.html#bertforquestionanswering): Bert Model with a span classification head on top for extractive question-answering tasks like SQuAD (a linear layers on top of the hidden-states output to compute span start logits and span end logits). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "import os\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.file_utils:PyTorch version 1.2.0 available.\n",
      "INFO:transformers.file_utils:TensorFlow version 2.1.0 available.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertModel, BertTokenizer, BertForSequenceClassification\n",
    "from torch.optim import Adam\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch import nn\n",
    "import wget\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/av6101604/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "INFO:transformers.configuration_utils:Model config BertConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": null,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "INFO:transformers.modeling_utils:loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /home/av6101604/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/av6101604/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    }
   ],
   "source": [
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/av6101604/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "INFO:transformers.configuration_utils:Model config BertConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": null,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "INFO:transformers.modeling_utils:loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /home/av6101604/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "INFO:transformers.modeling_utils:Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "INFO:transformers.modeling_utils:Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n"
     ]
    }
   ],
   "source": [
    "bert_sequence_model = BertForSequenceClassification.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_sequence_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input of BERT in the right format\n",
    "First, we need to get the input of BERT in the right format. BERT requires input to be in a specific format. \n",
    "![title](images/bert-embed.png)\n",
    "![title](images/processing_text_for_bert.png)\n",
    "\n",
    "**Attention Mask:**\n",
    "The “Attention Mask” is simply an array of 1s and 0s indicating which tokens are padding and which aren’t (seems kind of redundant, doesn’t it?!). This mask tells the “Self-Attention” mechanism in BERT not to incorporate these PAD tokens into its interpretation of the sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Manual appraoch: Steps for getting input in the right format.**\n",
    "BERT has two constraints:\n",
    "1. All sentences must be padded or truncated to a single, fixed length.\n",
    "2. The maximum sentence length is 512 tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example of using bert tokenizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['he', 'likes', 'to', 'work', 'with', 'em', '##bee', '##ding', '##s']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"he likes to work with embeedings\"\n",
    "tokens = tokenizer.tokenize(sentence)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Print the sentence mapped to token ids. Ie: String to Integer(stoi)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:  [2002, 7777, 2000, 2147, 2007, 7861, 11306, 4667, 2015]\n"
     ]
    }
   ],
   "source": [
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentence)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print tokens mapped into strings. Ie: Integer to String (itos)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String IDs:  ['he', 'likes', 'to', 'work', 'with', 'em', '##bee', '##ding', '##s']\n"
     ]
    }
   ],
   "source": [
    "print('String IDs: ', tokenizer.convert_ids_to_tokens([2002, 7777, 2000, 2147, 2007, 7861, 11306, 4667, 2015]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1:  ['he', 'likes', 'to', 'work', 'with', 'em', '##bee', '##ding', '##s'] \n",
      "\n",
      "Step 2:  ['[CLS]', 'he', 'likes', 'to', 'work', 'with', 'em', '##bee', '##ding', '##s', '[SEP]'] \n",
      "\n",
      "Step 3:  ['[CLS]', 'he', 'likes', 'to', 'work', 'with', 'em', '##bee', '##ding', '##s', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]'] \n",
      "\n",
      "Step 3:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "\n",
      "Step 4:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n",
      "\n",
      "Step 5:  [101, 2002, 7777, 2000, 2147, 2007, 7861, 11306, 4667, 2015, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "sentence = \"he likes to work with embeedings\"\n",
    "\n",
    "# Step 1: Tokenize\n",
    "tokens = tokenizer.tokenize(sentence)\n",
    "print(\"Step 1: \",tokens,\"\\n\")\n",
    "\n",
    "# Step 2: Add [CLS] and [SEP]\n",
    "tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
    "print(\"Step 2: \",tokens,\"\\n\")\n",
    "\n",
    "# Step 3: Pad tokens\n",
    "max_range = 20\n",
    "padded_tokens = tokens + ['[PAD]' for _ in range(max_range - len(tokens))]\n",
    "attn_mask = [1 if token != '[PAD]' else 0 for token in padded_tokens]\n",
    "print(\"Step 3: \", padded_tokens,\"\\n\")\n",
    "print(\"Step 3: \", attn_mask,\"\\n\")\n",
    "\n",
    "# Step 4: Segment ids\n",
    "# Since we're only feeding one sentence and it's not a pair, it will be all zero.\n",
    "seg_ids = [0 for _ in range(len(padded_tokens))] #Optional!\n",
    "print(\"Step 4: \", seg_ids, \"\\n\")\n",
    "\n",
    "# Step 5: Get BERT vocabulary index for each token\n",
    "token_ids = tokenizer.convert_tokens_to_ids(padded_tokens)\n",
    "print(\"Step 5: \", token_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feed into our model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert to pytorch tensors\n",
    "token_ids = torch.tensor(token_ids).unsqueeze(0)\n",
    "attn_mask = torch.tensor(attn_mask).unsqueeze(0)\n",
    "seg_ids = torch.tensor(seg_ids).unsqueeze(0)\n",
    "\n",
    "# Feed them to bert\n",
    "hidden_reps, cls_head = bert_model(token_ids, attention_mask = attn_mask, token_type_ids = seg_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **encode appraoch: Steps for getting input in the right format.**\n",
    "The transformers library provides a helpful encode function which will handle most of the parsing and data prep steps for us.\n",
    "**Documentation is [here](https://huggingface.co/transformers/main_classes/tokenizer.html?highlight=encode_plus#transformers.PreTrainedTokenizer.encode)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 2002, 7777, 2000, 2147, 2007, 7861, 11306, 4667, 2015, 102]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"he likes to work with embeedings\"\n",
    "token_ids = tokenizer.encode(sentence, add_special_tokens=True)\n",
    "token_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **encode_plus appraoch: Steps for getting input in the right format.**\n",
    "The tokenizer.encode_plus function combines multiple steps for us:\n",
    "\n",
    "1. Split the sentence into tokens.\n",
    "2. Add the special [CLS] and [SEP] tokens.\n",
    "3. Map the tokens to their IDs.\n",
    "4. Pad or truncate all sentences to the same length.\n",
    "5. Create the attention masks which explicitly differentiate real tokens from [PAD] tokens.\n",
    "\n",
    "The first four features are in tokenizer.encode, but I’m using tokenizer.encode_plus to get the fifth item (attention masks).\n",
    "**Documentation is [here.](https://huggingface.co/transformers/main_classes/tokenizer.html?highlight=encode_plus#transformers.PreTrainedTokenizer.encode_plus)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2002,  7777,  2000,  2147,  2007,  7861, 11306,  4667,  2015,\n",
       "            102,     0,     0,     0,     0,     0,     0,     0,     0,     0]]),\n",
       " 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"he likes to work with embeedings\"\n",
    "encoded_dict = tokenizer.encode_plus(\n",
    "                        sentence,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 20,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "\n",
    "token_ids = encoded_dict['input_ids']\n",
    "attn_mask = encoded_dict['attention_mask']\n",
    "seg_ids = encoded_dict['token_type_ids']\n",
    "\n",
    "hidden_reps, cls_head = bert_model(token_ids, attention_mask = attn_mask, token_type_ids = seg_ids)\n",
    "\n",
    "encoded_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Class and Data Loaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset...\n"
     ]
    }
   ],
   "source": [
    "print('Downloading dataset...')\n",
    "\n",
    "# The URL for the dataset zip file.\n",
    "url = 'https://raw.githubusercontent.com/theneuralbeing/bert-finetuning-webinar/master/data.zip'\n",
    "\n",
    "# Download the file and unzip it (if we haven't already)\n",
    "if not os.path.exists('./data.zip'):\n",
    "    wget.download(url, './data.zip')\n",
    "    !unzip -q data.zip\n",
    "    print('Unzipped Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadDataset(Dataset):\n",
    "\n",
    "    def __init__(self, filename, maxlen):\n",
    "\n",
    "        # Store the contents of the file in a pandas dataframe\n",
    "        self.df = pd.read_csv(filename, delimiter=',')\n",
    "\n",
    "        # Initialize the BERT tokenizer\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "        # Define the Maxlength for padding/truncating\n",
    "        self.maxlen = maxlen\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        # Selecting the sentence and label at the specified index in the data frame\n",
    "#         sentence = self.df.loc[index, 'review']\n",
    "#         label = self.df.loc[index, 'sentiment']\n",
    "        \n",
    "#         encoded_dict = self.tokenizer.encode_plus(\n",
    "#                         sentence,                      # Sentence to encode.\n",
    "#                         add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "#                         max_length = self.maxlen,           # Pad & truncate all sentences.\n",
    "#                         pad_to_max_length = True,\n",
    "#                         return_attention_mask = True,   # Construct attn. masks.\n",
    "#                         return_tensors = 'pt',     # Return pytorch tensors.\n",
    "#                    )\n",
    "#         return encoded_dict['input_ids'], encoded_dict['attention_mask'], label\n",
    "\n",
    "        #Selecting the sentence and label at the specified index in the data frame\n",
    "        sentence = self.df.loc[index, 'review']\n",
    "        label = self.df.loc[index, 'sentiment']\n",
    "\n",
    "        # Tokenize the sentence\n",
    "        tokens = self.tokenizer.tokenize(sentence)\n",
    "\n",
    "        # Inserting the CLS and SEP token at the beginning and end of the sentence\n",
    "        tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
    "        \n",
    "        # Padding/truncating the sentences to the maximum length\n",
    "        if len(tokens) < self.maxlen:\n",
    "            tokens = tokens + ['[PAD]' for _ in range(self.maxlen - len(tokens))]\n",
    "        else:\n",
    "            tokens = tokens[:self.maxlen-1] + ['[SEP]']\n",
    "        \n",
    "        # Convert the sequence to ids with BERT Vocabulary\n",
    "        tokens_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
    "        \n",
    "        # Converting the list to a pytorch tensor\n",
    "        tokens_ids_tensor = torch.tensor(tokens_ids)\n",
    "\n",
    "        # Obtaining the attention mask\n",
    "        attn_mask = (tokens_ids_tensor != 0).long()\n",
    "\n",
    "        return tokens_ids_tensor, attn_mask, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/av6101604/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/av6101604/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Creating instances of training and validation set\n",
    "train_set = LoadDataset(filename = 'data/train.csv', maxlen = 64)\n",
    "val_set = LoadDataset(filename = 'data/validation.csv', maxlen = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating intsances of training and validation dataloaders\n",
    "train_loader = DataLoader(train_set, batch_size = 32, num_workers = 5)\n",
    "val_loader = DataLoader(val_set, batch_size = 32, num_workers = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/av6101604/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "INFO:transformers.configuration_utils:Model config BertConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": null,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "INFO:transformers.modeling_utils:loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /home/av6101604/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n"
     ]
    }
   ],
   "source": [
    "bert_layer = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "for i, (seq, attn_masks, labels) in enumerate(train_loader):\n",
    "    hidden_reps, _ = bert_layer(seq, attn_masks)\n",
    "    \n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model using Pytorch Lighntning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentClassifier(pl.LightningModule):\n",
    "    def __init__(self, freeze_bert = True):\n",
    "        super(SentimentClassifier, self).__init__()\n",
    "\n",
    "        # Instantiating the BERT model object \n",
    "        self.bert_layer = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "        # Defining layers like dropout and linear\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifier = nn.Linear(768, 1)\n",
    "        \n",
    "        # loss function\n",
    "        self.criterion = BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, seq, attn_masks):\n",
    "        '''\n",
    "        Inputs:\n",
    "            -seq : Tensor of shape [B, T] containing token ids of sequences\n",
    "            -attn_masks : Tensor of shape [B, T] containing attention masks to be used to avoid contibution of PAD tokens\n",
    "        '''\n",
    "\n",
    "        # Getting contextualized representations from BERT Layer\n",
    "        cont_reps, _ = self.bert_layer(seq, attention_mask = attn_masks)\n",
    "\n",
    "        # Obtaining the representation of [CLS] head\n",
    "        cls_rep = cont_reps[:, 0]\n",
    "        # print('CLS shape: ',cls_rep.shape)\n",
    "\n",
    "        # Feeding cls_rep to the classifier layer\n",
    "        logits = self.classifier(cls_rep)\n",
    "        # print('Logits shape: ',logits.shape)\n",
    "\n",
    "        return logits\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return train_loader\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return val_loader\n",
    "    \n",
    "    def logits_accuracy(self, logits, labels):\n",
    "        probs = torch.sigmoid(logits.unsqueeze(-1))\n",
    "        preds = (probs > 0.5).long()\n",
    "        acc = (preds.squeeze() == labels).float().mean()\n",
    "        return acc\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return Adam(model.parameters(), lr = 2e-5)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # data from batch is same as 'next(enumerate(train_loader))[1]'\n",
    "        seq = batch[0]\n",
    "        attn_masks = batch[1]\n",
    "        labels = batch[2]\n",
    "        \n",
    "        logits = model(seq, attn_masks)\n",
    "        \n",
    "        loss = self.criterion(logits.squeeze(-1), labels.float())\n",
    "        \n",
    "        output = {\n",
    "            'loss': loss, # required\n",
    "            'progress_bar': {'training_loss':loss},\n",
    "        }\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def training_epoch_end(self, outputs):\n",
    "        epoch_acc = 0\n",
    "        for loss in outputs:\n",
    "            epoch_acc += loss['loss']\n",
    "        epoch_acc /= len(outputs)\n",
    "        \n",
    "        result = {\n",
    "            'log': {'train_epoch_acc':epoch_acc}\n",
    "        }\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        seq = batch[0]\n",
    "        attn_masks = batch[1]\n",
    "        labels = batch[2]\n",
    "        \n",
    "        val_logits = model(seq, attn_masks)\n",
    "\n",
    "        loss = self.criterion(val_logits.squeeze(-1), labels.float())\n",
    "        \n",
    "        val_acc = self.logits_accuracy(val_logits, labels)\n",
    "        \n",
    "        return {\n",
    "            'loss': loss,\n",
    "            'val_acc':val_acc\n",
    "        }\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        epoch_loss = 0\n",
    "        epoch_acc = 0\n",
    "        \n",
    "        for loss in outputs:\n",
    "            epoch_acc += loss['val_acc']\n",
    "        epoch_acc /= len(outputs)\n",
    "        \n",
    "        for loss in outputs:\n",
    "            epoch_loss += loss['loss']   \n",
    "        epoch_loss /= len(outputs)\n",
    "        \n",
    "        # Show this data into progress bar\n",
    "        tqdm_dict = {'val_epoch_acc': epoch_acc, 'val_epoch_loss':epoch_loss}\n",
    "\n",
    "        results = {\n",
    "        'progress_bar': tqdm_dict,\n",
    "        'log': {'val_acc': epoch_acc}\n",
    "        }\n",
    "        return results\n",
    "        \n",
    "        \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/av6101604/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "INFO:transformers.configuration_utils:Model config BertConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": null,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "INFO:transformers.modeling_utils:loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /home/av6101604/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "INFO:lightning:GPU available: True, used: True\n",
      "INFO:lightning:VISIBLE GPUS: 0\n",
      "/home/av6101604/env/lib64/python3.6/site-packages/pytorch_lightning/loggers/tensorboard.py:106: UserWarning: Hyperparameter logging is not available for Torch version 1.2.0. Skipping log_hyperparams. Upgrade to Torch 1.3.0 or above to enable hyperparameter logging.\n",
      "  f\"Hyperparameter logging is not available for Torch version {torch.__version__}.\"\n",
      "INFO:lightning:\n",
      "    | Name                                                   | Type              | Params\n",
      "-----------------------------------------------------------------------------------------\n",
      "0   | bert_layer                                             | BertModel         | 109 M \n",
      "1   | bert_layer.embeddings                                  | BertEmbeddings    | 23 M  \n",
      "2   | bert_layer.embeddings.word_embeddings                  | Embedding         | 23 M  \n",
      "3   | bert_layer.embeddings.position_embeddings              | Embedding         | 393 K \n",
      "4   | bert_layer.embeddings.token_type_embeddings            | Embedding         | 1 K   \n",
      "5   | bert_layer.embeddings.LayerNorm                        | LayerNorm         | 1 K   \n",
      "6   | bert_layer.embeddings.dropout                          | Dropout           | 0     \n",
      "7   | bert_layer.encoder                                     | BertEncoder       | 85 M  \n",
      "8   | bert_layer.encoder.layer                               | ModuleList        | 85 M  \n",
      "9   | bert_layer.encoder.layer.0                             | BertLayer         | 7 M   \n",
      "10  | bert_layer.encoder.layer.0.attention                   | BertAttention     | 2 M   \n",
      "11  | bert_layer.encoder.layer.0.attention.self              | BertSelfAttention | 1 M   \n",
      "12  | bert_layer.encoder.layer.0.attention.self.query        | Linear            | 590 K \n",
      "13  | bert_layer.encoder.layer.0.attention.self.key          | Linear            | 590 K \n",
      "14  | bert_layer.encoder.layer.0.attention.self.value        | Linear            | 590 K \n",
      "15  | bert_layer.encoder.layer.0.attention.self.dropout      | Dropout           | 0     \n",
      "16  | bert_layer.encoder.layer.0.attention.output            | BertSelfOutput    | 592 K \n",
      "17  | bert_layer.encoder.layer.0.attention.output.dense      | Linear            | 590 K \n",
      "18  | bert_layer.encoder.layer.0.attention.output.LayerNorm  | LayerNorm         | 1 K   \n",
      "19  | bert_layer.encoder.layer.0.attention.output.dropout    | Dropout           | 0     \n",
      "20  | bert_layer.encoder.layer.0.intermediate                | BertIntermediate  | 2 M   \n",
      "21  | bert_layer.encoder.layer.0.intermediate.dense          | Linear            | 2 M   \n",
      "22  | bert_layer.encoder.layer.0.output                      | BertOutput        | 2 M   \n",
      "23  | bert_layer.encoder.layer.0.output.dense                | Linear            | 2 M   \n",
      "24  | bert_layer.encoder.layer.0.output.LayerNorm            | LayerNorm         | 1 K   \n",
      "25  | bert_layer.encoder.layer.0.output.dropout              | Dropout           | 0     \n",
      "26  | bert_layer.encoder.layer.1                             | BertLayer         | 7 M   \n",
      "27  | bert_layer.encoder.layer.1.attention                   | BertAttention     | 2 M   \n",
      "28  | bert_layer.encoder.layer.1.attention.self              | BertSelfAttention | 1 M   \n",
      "29  | bert_layer.encoder.layer.1.attention.self.query        | Linear            | 590 K \n",
      "30  | bert_layer.encoder.layer.1.attention.self.key          | Linear            | 590 K \n",
      "31  | bert_layer.encoder.layer.1.attention.self.value        | Linear            | 590 K \n",
      "32  | bert_layer.encoder.layer.1.attention.self.dropout      | Dropout           | 0     \n",
      "33  | bert_layer.encoder.layer.1.attention.output            | BertSelfOutput    | 592 K \n",
      "34  | bert_layer.encoder.layer.1.attention.output.dense      | Linear            | 590 K \n",
      "35  | bert_layer.encoder.layer.1.attention.output.LayerNorm  | LayerNorm         | 1 K   \n",
      "36  | bert_layer.encoder.layer.1.attention.output.dropout    | Dropout           | 0     \n",
      "37  | bert_layer.encoder.layer.1.intermediate                | BertIntermediate  | 2 M   \n",
      "38  | bert_layer.encoder.layer.1.intermediate.dense          | Linear            | 2 M   \n",
      "39  | bert_layer.encoder.layer.1.output                      | BertOutput        | 2 M   \n",
      "40  | bert_layer.encoder.layer.1.output.dense                | Linear            | 2 M   \n",
      "41  | bert_layer.encoder.layer.1.output.LayerNorm            | LayerNorm         | 1 K   \n",
      "42  | bert_layer.encoder.layer.1.output.dropout              | Dropout           | 0     \n",
      "43  | bert_layer.encoder.layer.2                             | BertLayer         | 7 M   \n",
      "44  | bert_layer.encoder.layer.2.attention                   | BertAttention     | 2 M   \n",
      "45  | bert_layer.encoder.layer.2.attention.self              | BertSelfAttention | 1 M   \n",
      "46  | bert_layer.encoder.layer.2.attention.self.query        | Linear            | 590 K \n",
      "47  | bert_layer.encoder.layer.2.attention.self.key          | Linear            | 590 K \n",
      "48  | bert_layer.encoder.layer.2.attention.self.value        | Linear            | 590 K \n",
      "49  | bert_layer.encoder.layer.2.attention.self.dropout      | Dropout           | 0     \n",
      "50  | bert_layer.encoder.layer.2.attention.output            | BertSelfOutput    | 592 K \n",
      "51  | bert_layer.encoder.layer.2.attention.output.dense      | Linear            | 590 K \n",
      "52  | bert_layer.encoder.layer.2.attention.output.LayerNorm  | LayerNorm         | 1 K   \n",
      "53  | bert_layer.encoder.layer.2.attention.output.dropout    | Dropout           | 0     \n",
      "54  | bert_layer.encoder.layer.2.intermediate                | BertIntermediate  | 2 M   \n",
      "55  | bert_layer.encoder.layer.2.intermediate.dense          | Linear            | 2 M   \n",
      "56  | bert_layer.encoder.layer.2.output                      | BertOutput        | 2 M   \n",
      "57  | bert_layer.encoder.layer.2.output.dense                | Linear            | 2 M   \n",
      "58  | bert_layer.encoder.layer.2.output.LayerNorm            | LayerNorm         | 1 K   \n",
      "59  | bert_layer.encoder.layer.2.output.dropout              | Dropout           | 0     \n",
      "60  | bert_layer.encoder.layer.3                             | BertLayer         | 7 M   \n",
      "61  | bert_layer.encoder.layer.3.attention                   | BertAttention     | 2 M   \n",
      "62  | bert_layer.encoder.layer.3.attention.self              | BertSelfAttention | 1 M   \n",
      "63  | bert_layer.encoder.layer.3.attention.self.query        | Linear            | 590 K \n",
      "64  | bert_layer.encoder.layer.3.attention.self.key          | Linear            | 590 K \n",
      "65  | bert_layer.encoder.layer.3.attention.self.value        | Linear            | 590 K \n",
      "66  | bert_layer.encoder.layer.3.attention.self.dropout      | Dropout           | 0     \n",
      "67  | bert_layer.encoder.layer.3.attention.output            | BertSelfOutput    | 592 K \n",
      "68  | bert_layer.encoder.layer.3.attention.output.dense      | Linear            | 590 K \n",
      "69  | bert_layer.encoder.layer.3.attention.output.LayerNorm  | LayerNorm         | 1 K   \n",
      "70  | bert_layer.encoder.layer.3.attention.output.dropout    | Dropout           | 0     \n",
      "71  | bert_layer.encoder.layer.3.intermediate                | BertIntermediate  | 2 M   \n",
      "72  | bert_layer.encoder.layer.3.intermediate.dense          | Linear            | 2 M   \n",
      "73  | bert_layer.encoder.layer.3.output                      | BertOutput        | 2 M   \n",
      "74  | bert_layer.encoder.layer.3.output.dense                | Linear            | 2 M   \n",
      "75  | bert_layer.encoder.layer.3.output.LayerNorm            | LayerNorm         | 1 K   \n",
      "76  | bert_layer.encoder.layer.3.output.dropout              | Dropout           | 0     \n",
      "77  | bert_layer.encoder.layer.4                             | BertLayer         | 7 M   \n",
      "78  | bert_layer.encoder.layer.4.attention                   | BertAttention     | 2 M   \n",
      "79  | bert_layer.encoder.layer.4.attention.self              | BertSelfAttention | 1 M   \n",
      "80  | bert_layer.encoder.layer.4.attention.self.query        | Linear            | 590 K \n",
      "81  | bert_layer.encoder.layer.4.attention.self.key          | Linear            | 590 K \n",
      "82  | bert_layer.encoder.layer.4.attention.self.value        | Linear            | 590 K \n",
      "83  | bert_layer.encoder.layer.4.attention.self.dropout      | Dropout           | 0     \n",
      "84  | bert_layer.encoder.layer.4.attention.output            | BertSelfOutput    | 592 K \n",
      "85  | bert_layer.encoder.layer.4.attention.output.dense      | Linear            | 590 K \n",
      "86  | bert_layer.encoder.layer.4.attention.output.LayerNorm  | LayerNorm         | 1 K   \n",
      "87  | bert_layer.encoder.layer.4.attention.output.dropout    | Dropout           | 0     \n",
      "88  | bert_layer.encoder.layer.4.intermediate                | BertIntermediate  | 2 M   \n",
      "89  | bert_layer.encoder.layer.4.intermediate.dense          | Linear            | 2 M   \n",
      "90  | bert_layer.encoder.layer.4.output                      | BertOutput        | 2 M   \n",
      "91  | bert_layer.encoder.layer.4.output.dense                | Linear            | 2 M   \n",
      "92  | bert_layer.encoder.layer.4.output.LayerNorm            | LayerNorm         | 1 K   \n",
      "93  | bert_layer.encoder.layer.4.output.dropout              | Dropout           | 0     \n",
      "94  | bert_layer.encoder.layer.5                             | BertLayer         | 7 M   \n",
      "95  | bert_layer.encoder.layer.5.attention                   | BertAttention     | 2 M   \n",
      "96  | bert_layer.encoder.layer.5.attention.self              | BertSelfAttention | 1 M   \n",
      "97  | bert_layer.encoder.layer.5.attention.self.query        | Linear            | 590 K \n",
      "98  | bert_layer.encoder.layer.5.attention.self.key          | Linear            | 590 K \n",
      "99  | bert_layer.encoder.layer.5.attention.self.value        | Linear            | 590 K \n",
      "100 | bert_layer.encoder.layer.5.attention.self.dropout      | Dropout           | 0     \n",
      "101 | bert_layer.encoder.layer.5.attention.output            | BertSelfOutput    | 592 K \n",
      "102 | bert_layer.encoder.layer.5.attention.output.dense      | Linear            | 590 K \n",
      "103 | bert_layer.encoder.layer.5.attention.output.LayerNorm  | LayerNorm         | 1 K   \n",
      "104 | bert_layer.encoder.layer.5.attention.output.dropout    | Dropout           | 0     \n",
      "105 | bert_layer.encoder.layer.5.intermediate                | BertIntermediate  | 2 M   \n",
      "106 | bert_layer.encoder.layer.5.intermediate.dense          | Linear            | 2 M   \n",
      "107 | bert_layer.encoder.layer.5.output                      | BertOutput        | 2 M   \n",
      "108 | bert_layer.encoder.layer.5.output.dense                | Linear            | 2 M   \n",
      "109 | bert_layer.encoder.layer.5.output.LayerNorm            | LayerNorm         | 1 K   \n",
      "110 | bert_layer.encoder.layer.5.output.dropout              | Dropout           | 0     \n",
      "111 | bert_layer.encoder.layer.6                             | BertLayer         | 7 M   \n",
      "112 | bert_layer.encoder.layer.6.attention                   | BertAttention     | 2 M   \n",
      "113 | bert_layer.encoder.layer.6.attention.self              | BertSelfAttention | 1 M   \n",
      "114 | bert_layer.encoder.layer.6.attention.self.query        | Linear            | 590 K \n",
      "115 | bert_layer.encoder.layer.6.attention.self.key          | Linear            | 590 K \n",
      "116 | bert_layer.encoder.layer.6.attention.self.value        | Linear            | 590 K \n",
      "117 | bert_layer.encoder.layer.6.attention.self.dropout      | Dropout           | 0     \n",
      "118 | bert_layer.encoder.layer.6.attention.output            | BertSelfOutput    | 592 K \n",
      "119 | bert_layer.encoder.layer.6.attention.output.dense      | Linear            | 590 K \n",
      "120 | bert_layer.encoder.layer.6.attention.output.LayerNorm  | LayerNorm         | 1 K   \n",
      "121 | bert_layer.encoder.layer.6.attention.output.dropout    | Dropout           | 0     \n",
      "122 | bert_layer.encoder.layer.6.intermediate                | BertIntermediate  | 2 M   \n",
      "123 | bert_layer.encoder.layer.6.intermediate.dense          | Linear            | 2 M   \n",
      "124 | bert_layer.encoder.layer.6.output                      | BertOutput        | 2 M   \n",
      "125 | bert_layer.encoder.layer.6.output.dense                | Linear            | 2 M   \n",
      "126 | bert_layer.encoder.layer.6.output.LayerNorm            | LayerNorm         | 1 K   \n",
      "127 | bert_layer.encoder.layer.6.output.dropout              | Dropout           | 0     \n",
      "128 | bert_layer.encoder.layer.7                             | BertLayer         | 7 M   \n",
      "129 | bert_layer.encoder.layer.7.attention                   | BertAttention     | 2 M   \n",
      "130 | bert_layer.encoder.layer.7.attention.self              | BertSelfAttention | 1 M   \n",
      "131 | bert_layer.encoder.layer.7.attention.self.query        | Linear            | 590 K \n",
      "132 | bert_layer.encoder.layer.7.attention.self.key          | Linear            | 590 K \n",
      "133 | bert_layer.encoder.layer.7.attention.self.value        | Linear            | 590 K \n",
      "134 | bert_layer.encoder.layer.7.attention.self.dropout      | Dropout           | 0     \n",
      "135 | bert_layer.encoder.layer.7.attention.output            | BertSelfOutput    | 592 K \n",
      "136 | bert_layer.encoder.layer.7.attention.output.dense      | Linear            | 590 K \n",
      "137 | bert_layer.encoder.layer.7.attention.output.LayerNorm  | LayerNorm         | 1 K   \n",
      "138 | bert_layer.encoder.layer.7.attention.output.dropout    | Dropout           | 0     \n",
      "139 | bert_layer.encoder.layer.7.intermediate                | BertIntermediate  | 2 M   \n",
      "140 | bert_layer.encoder.layer.7.intermediate.dense          | Linear            | 2 M   \n",
      "141 | bert_layer.encoder.layer.7.output                      | BertOutput        | 2 M   \n",
      "142 | bert_layer.encoder.layer.7.output.dense                | Linear            | 2 M   \n",
      "143 | bert_layer.encoder.layer.7.output.LayerNorm            | LayerNorm         | 1 K   \n",
      "144 | bert_layer.encoder.layer.7.output.dropout              | Dropout           | 0     \n",
      "145 | bert_layer.encoder.layer.8                             | BertLayer         | 7 M   \n",
      "146 | bert_layer.encoder.layer.8.attention                   | BertAttention     | 2 M   \n",
      "147 | bert_layer.encoder.layer.8.attention.self              | BertSelfAttention | 1 M   \n",
      "148 | bert_layer.encoder.layer.8.attention.self.query        | Linear            | 590 K \n",
      "149 | bert_layer.encoder.layer.8.attention.self.key          | Linear            | 590 K \n",
      "150 | bert_layer.encoder.layer.8.attention.self.value        | Linear            | 590 K \n",
      "151 | bert_layer.encoder.layer.8.attention.self.dropout      | Dropout           | 0     \n",
      "152 | bert_layer.encoder.layer.8.attention.output            | BertSelfOutput    | 592 K \n",
      "153 | bert_layer.encoder.layer.8.attention.output.dense      | Linear            | 590 K \n",
      "154 | bert_layer.encoder.layer.8.attention.output.LayerNorm  | LayerNorm         | 1 K   \n",
      "155 | bert_layer.encoder.layer.8.attention.output.dropout    | Dropout           | 0     \n",
      "156 | bert_layer.encoder.layer.8.intermediate                | BertIntermediate  | 2 M   \n",
      "157 | bert_layer.encoder.layer.8.intermediate.dense          | Linear            | 2 M   \n",
      "158 | bert_layer.encoder.layer.8.output                      | BertOutput        | 2 M   \n",
      "159 | bert_layer.encoder.layer.8.output.dense                | Linear            | 2 M   \n",
      "160 | bert_layer.encoder.layer.8.output.LayerNorm            | LayerNorm         | 1 K   \n",
      "161 | bert_layer.encoder.layer.8.output.dropout              | Dropout           | 0     \n",
      "162 | bert_layer.encoder.layer.9                             | BertLayer         | 7 M   \n",
      "163 | bert_layer.encoder.layer.9.attention                   | BertAttention     | 2 M   \n",
      "164 | bert_layer.encoder.layer.9.attention.self              | BertSelfAttention | 1 M   \n",
      "165 | bert_layer.encoder.layer.9.attention.self.query        | Linear            | 590 K \n",
      "166 | bert_layer.encoder.layer.9.attention.self.key          | Linear            | 590 K \n",
      "167 | bert_layer.encoder.layer.9.attention.self.value        | Linear            | 590 K \n",
      "168 | bert_layer.encoder.layer.9.attention.self.dropout      | Dropout           | 0     \n",
      "169 | bert_layer.encoder.layer.9.attention.output            | BertSelfOutput    | 592 K \n",
      "170 | bert_layer.encoder.layer.9.attention.output.dense      | Linear            | 590 K \n",
      "171 | bert_layer.encoder.layer.9.attention.output.LayerNorm  | LayerNorm         | 1 K   \n",
      "172 | bert_layer.encoder.layer.9.attention.output.dropout    | Dropout           | 0     \n",
      "173 | bert_layer.encoder.layer.9.intermediate                | BertIntermediate  | 2 M   \n",
      "174 | bert_layer.encoder.layer.9.intermediate.dense          | Linear            | 2 M   \n",
      "175 | bert_layer.encoder.layer.9.output                      | BertOutput        | 2 M   \n",
      "176 | bert_layer.encoder.layer.9.output.dense                | Linear            | 2 M   \n",
      "177 | bert_layer.encoder.layer.9.output.LayerNorm            | LayerNorm         | 1 K   \n",
      "178 | bert_layer.encoder.layer.9.output.dropout              | Dropout           | 0     \n",
      "179 | bert_layer.encoder.layer.10                            | BertLayer         | 7 M   \n",
      "180 | bert_layer.encoder.layer.10.attention                  | BertAttention     | 2 M   \n",
      "181 | bert_layer.encoder.layer.10.attention.self             | BertSelfAttention | 1 M   \n",
      "182 | bert_layer.encoder.layer.10.attention.self.query       | Linear            | 590 K \n",
      "183 | bert_layer.encoder.layer.10.attention.self.key         | Linear            | 590 K \n",
      "184 | bert_layer.encoder.layer.10.attention.self.value       | Linear            | 590 K \n",
      "185 | bert_layer.encoder.layer.10.attention.self.dropout     | Dropout           | 0     \n",
      "186 | bert_layer.encoder.layer.10.attention.output           | BertSelfOutput    | 592 K \n",
      "187 | bert_layer.encoder.layer.10.attention.output.dense     | Linear            | 590 K \n",
      "188 | bert_layer.encoder.layer.10.attention.output.LayerNorm | LayerNorm         | 1 K   \n",
      "189 | bert_layer.encoder.layer.10.attention.output.dropout   | Dropout           | 0     \n",
      "190 | bert_layer.encoder.layer.10.intermediate               | BertIntermediate  | 2 M   \n",
      "191 | bert_layer.encoder.layer.10.intermediate.dense         | Linear            | 2 M   \n",
      "192 | bert_layer.encoder.layer.10.output                     | BertOutput        | 2 M   \n",
      "193 | bert_layer.encoder.layer.10.output.dense               | Linear            | 2 M   \n",
      "194 | bert_layer.encoder.layer.10.output.LayerNorm           | LayerNorm         | 1 K   \n",
      "195 | bert_layer.encoder.layer.10.output.dropout             | Dropout           | 0     \n",
      "196 | bert_layer.encoder.layer.11                            | BertLayer         | 7 M   \n",
      "197 | bert_layer.encoder.layer.11.attention                  | BertAttention     | 2 M   \n",
      "198 | bert_layer.encoder.layer.11.attention.self             | BertSelfAttention | 1 M   \n",
      "199 | bert_layer.encoder.layer.11.attention.self.query       | Linear            | 590 K \n",
      "200 | bert_layer.encoder.layer.11.attention.self.key         | Linear            | 590 K \n",
      "201 | bert_layer.encoder.layer.11.attention.self.value       | Linear            | 590 K \n",
      "202 | bert_layer.encoder.layer.11.attention.self.dropout     | Dropout           | 0     \n",
      "203 | bert_layer.encoder.layer.11.attention.output           | BertSelfOutput    | 592 K \n",
      "204 | bert_layer.encoder.layer.11.attention.output.dense     | Linear            | 590 K \n",
      "205 | bert_layer.encoder.layer.11.attention.output.LayerNorm | LayerNorm         | 1 K   \n",
      "206 | bert_layer.encoder.layer.11.attention.output.dropout   | Dropout           | 0     \n",
      "207 | bert_layer.encoder.layer.11.intermediate               | BertIntermediate  | 2 M   \n",
      "208 | bert_layer.encoder.layer.11.intermediate.dense         | Linear            | 2 M   \n",
      "209 | bert_layer.encoder.layer.11.output                     | BertOutput        | 2 M   \n",
      "210 | bert_layer.encoder.layer.11.output.dense               | Linear            | 2 M   \n",
      "211 | bert_layer.encoder.layer.11.output.LayerNorm           | LayerNorm         | 1 K   \n",
      "212 | bert_layer.encoder.layer.11.output.dropout             | Dropout           | 0     \n",
      "213 | bert_layer.pooler                                      | BertPooler        | 590 K \n",
      "214 | bert_layer.pooler.dense                                | Linear            | 590 K \n",
      "215 | bert_layer.pooler.activation                           | Tanh              | 0     \n",
      "216 | dropout                                                | Dropout           | 0     \n",
      "217 | classifier                                             | Linear            | 769   \n",
      "218 | criterion                                              | BCEWithLogitsLoss | 0     \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validation sanity check', layout=Layout(flex='2'), max=5.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bb5462178294e6ea96eeabda7f60acc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=1.0), HTML(value='')), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/av6101604/env/lib64/python3.6/site-packages/pytorch_lightning/utilities/warnings.py:18: RuntimeWarning: Displayed epoch numbers in the progress bar start from \"1\" until v0.6.x, but will start from \"0\" in v0.8.0.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Validating', layout=Layout(flex='2'), max=782.0, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/av6101604/env/lib64/python3.6/site-packages/pytorch_lightning/utilities/warnings.py:18: RuntimeWarning: Can save best model only with val_loss available, skipping.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SentimentClassifier()\n",
    "trainer = Trainer(gpus=1, max_epochs=1)#max_epochs=4)\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sentence, maxlen=64):\n",
    "\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    # Tokenize the sentence\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "\n",
    "    # Inserting the CLS and SEP token at the beginning and end of the sentence\n",
    "    tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
    "    \n",
    "    # Padding/truncating the sentences to the maximum length\n",
    "    if len(tokens) < maxlen:\n",
    "        tokens = tokens + ['[PAD]' for _ in range(maxlen - len(tokens))]\n",
    "    else:\n",
    "        tokens = tokens[:maxlen-1] + ['[SEP]']\n",
    "    \n",
    "    # Convert the sequence to ids with BERT Vocabulary\n",
    "    tokens_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    \n",
    "    # Converting the list to a pytorch tensor\n",
    "    tokens_ids_tensor = torch.tensor(tokens_ids).unsqueeze(0)\n",
    "\n",
    "    # Obtaining the attention mask\n",
    "    attn_mask = (tokens_ids_tensor != 0).long()\n",
    "\n",
    "    return tokens_ids_tensor, attn_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining an evaluation function for training \n",
    "def predict(net, iseq, masks):\n",
    "    device = 'cpu'\n",
    "    # Setting model to evaluation mode\n",
    "    net.eval()\n",
    "\n",
    "    # Move inputs and targets to device\n",
    "    iseq, masks = iseq.to(device), masks.to(device)\n",
    "\n",
    "    # Get logit predictions\n",
    "    p_logit = net(iseq, masks)\n",
    "\n",
    "    probs = torch.sigmoid(p_logit.unsqueeze(-1))\n",
    "    preds = (probs > 0.5).long().squeeze(0)\n",
    "\n",
    "   \n",
    "    return preds, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/av6101604/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    }
   ],
   "source": [
    "test_tokens, test_attn = preprocess('the literally love this movie ever')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1]]) tensor([[[0.9665]]], grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = model.to('cpu')\n",
    "pred, probability = predict(model, test_tokens, test_attn)\n",
    "print(pred, probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "278px",
    "left": "1580px",
    "right": "20px",
    "top": "120px",
    "width": "320px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
